{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-07-18T04:22:55.956524Z","iopub.status.busy":"2021-07-18T04:22:55.955919Z","iopub.status.idle":"2021-07-18T04:22:56.527271Z","shell.execute_reply":"2021-07-18T04:22:56.526277Z","shell.execute_reply.started":"2021-07-18T04:22:55.956406Z"}},"source":["# Import things"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:07.261649Z","iopub.status.busy":"2024-07-11T09:25:07.261283Z","iopub.status.idle":"2024-07-11T09:25:08.874112Z","shell.execute_reply":"2024-07-11T09:25:08.873208Z","shell.execute_reply.started":"2024-07-11T09:25:07.261619Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/Omid-Nejati/MedViT"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:08.876356Z","iopub.status.busy":"2024-07-11T09:25:08.876032Z","iopub.status.idle":"2024-07-11T09:25:13.599736Z","shell.execute_reply":"2024-07-11T09:25:13.598926Z","shell.execute_reply.started":"2024-07-11T09:25:08.876325Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchvision.utils\n","from torchvision import models\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:13.601758Z","iopub.status.busy":"2024-07-11T09:25:13.601019Z","iopub.status.idle":"2024-07-11T09:25:39.243989Z","shell.execute_reply":"2024-07-11T09:25:39.242785Z","shell.execute_reply.started":"2024-07-11T09:25:13.601716Z"},"trusted":true},"outputs":[],"source":["!pip install timm\n","!pip install einops"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:39.246925Z","iopub.status.busy":"2024-07-11T09:25:39.246604Z","iopub.status.idle":"2024-07-11T09:25:39.251858Z","shell.execute_reply":"2024-07-11T09:25:39.250809Z","shell.execute_reply.started":"2024-07-11T09:25:39.246894Z"},"trusted":true},"outputs":[],"source":["package_path = \"/kaggle/input/medvit-for-brain-tumor/MedViT\"\n","import sys \n","sys.path.append(package_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:39.253472Z","iopub.status.busy":"2024-07-11T09:25:39.253095Z","iopub.status.idle":"2024-07-11T09:25:40.440060Z","shell.execute_reply":"2024-07-11T09:25:40.439202Z","shell.execute_reply.started":"2024-07-11T09:25:39.253438Z"},"trusted":true},"outputs":[],"source":["from MedViT import MedViT_base"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:40.441578Z","iopub.status.busy":"2024-07-11T09:25:40.441283Z","iopub.status.idle":"2024-07-11T09:25:52.877670Z","shell.execute_reply":"2024-07-11T09:25:52.876598Z","shell.execute_reply.started":"2024-07-11T09:25:40.441550Z"},"trusted":true},"outputs":[],"source":["!pip install config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:52.879517Z","iopub.status.busy":"2024-07-11T09:25:52.879192Z","iopub.status.idle":"2024-07-11T09:25:52.887342Z","shell.execute_reply":"2024-07-11T09:25:52.886483Z","shell.execute_reply.started":"2024-07-11T09:25:52.879480Z"},"trusted":true},"outputs":[],"source":["MedViT_base"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:52.888780Z","iopub.status.busy":"2024-07-11T09:25:52.888510Z","iopub.status.idle":"2024-07-11T09:25:54.275237Z","shell.execute_reply":"2024-07-11T09:25:54.274223Z","shell.execute_reply.started":"2024-07-11T09:25:52.888755Z"},"trusted":true},"outputs":[],"source":["package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\n","import sys \n","sys.path.append(package_path)\n","\n","import os\n","import glob\n","import time\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import pydicom\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch.utils import data as torch_data\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import Dataset, DataLoader\n","import pydicom\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","\n","import efficientnet_pytorch\n","\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.277068Z","iopub.status.busy":"2024-07-11T09:25:54.276606Z","iopub.status.idle":"2024-07-11T09:25:54.310865Z","shell.execute_reply":"2024-07-11T09:25:54.309916Z","shell.execute_reply.started":"2024-07-11T09:25:54.277039Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","seed = 123\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(seed)\n","\n","class CFG:\n","    cnn_features = 256\n","    lstm_hidden = 32\n","    n_heads = 4\n","    proj_dim = 128  \n","    n_fold = 4\n","    n_epochs = 20\n","    img_size = 256\n","    n_frames = 40  \n","    cnn_features = 512\n","    n_heads = 16\n","    proj_dim = 128\n","    batch_size = 8"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.353460Z","iopub.status.busy":"2024-07-11T09:25:54.353197Z","iopub.status.idle":"2024-07-11T09:25:54.366955Z","shell.execute_reply":"2024-07-11T09:25:54.366204Z","shell.execute_reply.started":"2024-07-11T09:25:54.353436Z"},"trusted":true},"outputs":[],"source":["def load_medvit_weights(model, weight_path):\n","    state_dict = torch.load(weight_path)\n","    model.load_state_dict(state_dict, strict=False)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.368527Z","iopub.status.busy":"2024-07-11T09:25:54.368254Z","iopub.status.idle":"2024-07-11T09:25:54.385529Z","shell.execute_reply":"2024-07-11T09:25:54.384543Z","shell.execute_reply.started":"2024-07-11T09:25:54.368490Z"},"trusted":true},"outputs":[],"source":["class MedViT3D(nn.Module):\n","    def __init__(self, num_classes, patch_size):\n","        super(MedViT3D, self).__init__()\n","        self.num_classes = num_classes\n","        self.patch_size = patch_size\n","        self.hidden_dim = 768\n","        self.num_heads = CFG.n_heads\n","        self.dropout_rate = 0.001\n","        \n","        self.patch_embeddings = nn.Conv3d(in_channels=4, out_channels=self.hidden_dim, \n","                                          kernel_size=self.patch_size, stride=self.patch_size)\n","        \n","\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=self.hidden_dim, nhead=self.num_heads, dropout=self.dropout_rate)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n","        \n","        self.fc = nn.Linear(self.hidden_dim, self.num_classes)\n","        self.dropout = nn.Dropout(self.dropout_rate)\n","\n","    def forward(self, x):\n","        x = self.patch_embeddings(x)  \n","        x = x.flatten(2) \n","        x = x.transpose(1, 2)  \n","        x = self.transformer_encoder(x)  \n","        x = x.mean(dim=1)  \n","        x = self.fc(self.dropout(x))  \n","        return x\n","\n","class MedViTModel(nn.Module):\n","    def __init__(self):\n","        super(MedViTModel, self).__init__()\n","        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)  # Convert 4 channels to 3 channels\n","        self.net = nn.ModuleList([\n","            MedViT3D(num_classes=CFG.cnn_features, patch_size=16),\n","            MedViT3D(num_classes=CFG.cnn_features, patch_size=32),\n","            MedViT3D(num_classes=CFG.cnn_features, patch_size=16),\n","            MedViT3D(num_classes=CFG.cnn_features, patch_size=32)\n","        ])\n","\n","    def forward(self, x):\n","        out = []\n","        for model in self.net:\n","            out.append(model(x))\n","        out = torch.stack(out, dim=1) \n","        return out\n","\n","class SeparableEmbedding(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super(SeparableEmbedding, self).__init__()\n","        self.fc = nn.Linear(input_dim, output_dim)\n","\n","    def forward(self, x):\n","        return F.relu(self.fc(x))\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.medvit = MedViTModel()\n","        self.embedding = SeparableEmbedding(CFG.cnn_features, CFG.proj_dim)\n","        self.fc = nn.Linear(CFG.proj_dim * 4, 1, bias=True)  \n","    def forward(self, x):\n","        batch_size, timesteps, C, H, W = x.size()\n","        medvit_out = self.medvit(x)\n","        embedding_output = self.embedding(medvit_out)\n","        embedding_output = embedding_output.view(batch_size, -1)\n","        out = self.fc(embedding_output)\n","        return out\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.431461Z","iopub.status.busy":"2024-07-11T09:25:54.430890Z","iopub.status.idle":"2024-07-11T09:25:54.445607Z","shell.execute_reply":"2024-07-11T09:25:54.444810Z","shell.execute_reply.started":"2024-07-11T09:25:54.431435Z"},"trusted":true},"outputs":[],"source":["def load_image(path):\n","    ext = os.path.splitext(path)[-1].lower()\n","    if ext == '.png':\n","        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","        if image is None:\n","            return np.zeros((CFG.img_size, CFG.img_size))\n","        image = cv2.resize(image, (CFG.img_size, CFG.img_size))\n","        return image.astype('float32') / 255\n","    else:\n","        try:\n","            dicom = pydicom.dcmread(path, force=True)\n","            image = apply_voi_lut(dicom.pixel_array, dicom)\n","            image = cv2.resize(image, (CFG.img_size, CFG.img_size))\n","            image = image - np.min(image)\n","            if np.min(image) < np.max(image):\n","                image = image / np.max(image)\n","            return image.astype('float32')\n","        except (pydicom.errors.InvalidDicomError, AttributeError):\n","            print(f\"Error reading DICOM file: {path}\")\n","            return np.zeros((CFG.img_size, CFG.img_size))\n","\n","def load_3d_image(dicom_paths):\n","    slices = []\n","    for path in dicom_paths: \n","        x = load_image(path)\n","        try:\n","            slices.append(x)\n","        except:\n","            print(type(x))\n","            return\n","            \n","    if len(slices) == 0:\n","        return np.zeros((CFG.img_size, CFG.img_size, CFG.n_frames))\n","    \n","    volume = np.stack(slices, axis=-1)\n","    \n","    if volume.shape[-1] < CFG.n_frames:\n","        pad_width = CFG.n_frames - volume.shape[-1]\n","        volume = np.pad(volume, ((0, 0), (0, 0), (0, pad_width)), mode='constant')\n","    elif volume.shape[-1] > CFG.n_frames:\n","        indices = np.linspace(0, volume.shape[-1] - 1, CFG.n_frames).astype(int)\n","        volume = volume[:, :, indices]\n","    return volume\n","\n","\n","def uniform_temporal_subsample(x, num_samples):\n","    t = len(x)\n","    indices = torch.linspace(0, t - 1, num_samples)\n","    indices = torch.clamp(indices, 0, t - 1).long()\n","    return [x[i] for i in indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.446906Z","iopub.status.busy":"2024-07-11T09:25:54.446647Z","iopub.status.idle":"2024-07-11T09:25:54.460671Z","shell.execute_reply":"2024-07-11T09:25:54.459853Z","shell.execute_reply.started":"2024-07-11T09:25:54.446882Z"},"trusted":true},"outputs":[],"source":["class DataRetriever(Dataset):\n","    def __init__(self, paths, targets, transform=None):\n","        self.paths = paths\n","        self.targets = targets\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def read_video(self, vid_paths):\n","        video = [load_3d_image(vid_paths)]\n","        if self.transform:\n","            seed = random.randint(0, 99999)\n","            for i in range(len(video)):\n","                random.seed(seed)\n","                video[i] = self.transform(image=video[i])[\"image\"]\n","\n","        video = [torch.tensor(frame, dtype=torch.float32) for frame in video]\n","        if len(video) == 0:\n","            video = torch.zeros((CFG.img_size, CFG.img_size, CFG.n_frames))\n","        else:\n","            video = torch.stack(video)  # H * W * D\n","        return video\n","\n","    def __getitem__(self, index):\n","        _id = self.paths[index]\n","        patient_path = f\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/{str(_id).zfill(5)}/\"\n","        channels = []\n","        for t in [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]:\n","            t_paths = sorted(\n","                glob.glob(os.path.join(patient_path, t, \"*\")), \n","                key=lambda x: int(os.path.basename(x).split(\"-\")[-1].split(\".\")[0]),\n","            )\n","            channel = load_3d_image(t_paths)\n","            if channel.shape[-1] == 0:\n","                print(f\"Empty channel detected for patient {_id}, type {t}\")\n","                channel = np.zeros((CFG.img_size, CFG.img_size, CFG.n_frames))\n","            channels.append(torch.tensor(channel, dtype=torch.float32))\n","\n","        channels = torch.stack(channels)  # (channels, H, W, D)\n","        y = torch.tensor(self.targets[index], dtype=torch.float32)\n","        return {\"X\": channels, \"y\": y}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.462007Z","iopub.status.busy":"2024-07-11T09:25:54.461749Z","iopub.status.idle":"2024-07-11T09:25:54.652380Z","shell.execute_reply":"2024-07-11T09:25:54.651619Z","shell.execute_reply.started":"2024-07-11T09:25:54.461983Z"},"trusted":true},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","#Data augmentation\n","train_transform = A.Compose([\n","                                A.HorizontalFlip(p=0.5),\n","                                A.ShiftScaleRotate(\n","                                    shift_limit=0.0625, \n","                                    scale_limit=0.1, \n","                                    rotate_limit=10, \n","                                    p=0.5\n","                                ),\n","                                A.RandomBrightnessContrast(p=0.5),\n","                            ])\n","valid_transform = A.Compose([\n","                            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.658881Z","iopub.status.busy":"2024-07-11T09:25:54.658606Z","iopub.status.idle":"2024-07-11T09:25:54.687723Z","shell.execute_reply":"2024-07-11T09:25:54.686891Z","shell.execute_reply.started":"2024-07-11T09:25:54.658856Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n","df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.694480Z","iopub.status.busy":"2024-07-11T09:25:54.694195Z","iopub.status.idle":"2024-07-11T09:25:54.704079Z","shell.execute_reply":"2024-07-11T09:25:54.703375Z","shell.execute_reply.started":"2024-07-11T09:25:54.694447Z"},"trusted":true},"outputs":[],"source":["class LossMeter:\n","    def __init__(self):\n","        self.avg = 0\n","        self.n = 0\n","    \n","    def reset(self):\n","        self.avg = 0\n","        self.n = 0\n","\n","    def update(self, val):\n","        self.n += 1\n","        # incremental update\n","        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n","\n","class AccMeter:\n","    def __init__(self):\n","        self.avg = 0\n","        self.n = 0\n","        \n","    def reset(self):\n","        self.avg = 0\n","        self.n = 0\n","        \n","    def update(self, y_true, y_pred):\n","        y_true = y_true.cpu().numpy().astype(int)\n","        y_pred = y_pred.detach().cpu().numpy() >= 0  \n","        last_n = self.n\n","        self.n += len(y_true)\n","        true_count = np.sum(y_true == y_pred)\n","        # incremental update\n","        self.avg = true_count / self.n + last_n / self.n * self.avg\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.705890Z","iopub.status.busy":"2024-07-11T09:25:54.705429Z","iopub.status.idle":"2024-07-11T09:25:54.742396Z","shell.execute_reply":"2024-07-11T09:25:54.741694Z","shell.execute_reply.started":"2024-07-11T09:25:54.705857Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(self, model, device, optimizer, criterion, loss_meter, score_meter, accumulation_steps=1):\n","        self.model = model\n","        self.device = device\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.loss_meter = loss_meter\n","        self.score_meter = score_meter\n","        self.hist = {\n","            'val_loss': [],\n","            'val_score': [],\n","            'train_loss': [],\n","            'train_score': []\n","        }\n","        \n","        self.best_valid_score = -np.inf\n","        self.best_valid_loss = np.inf\n","        self.best_train_score = -np.inf\n","        self.n_patience = 0\n","        \n","        self.messages = {\n","            \"epoch\": \"[Epoch {}: {}] loss: {:.9f}, score: {:.9f}, time: {} s\",\n","            \"checkpoint\": \"The score improved from {:.9f} to {:.9f}. Save model to '{}'\",\n","            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n","        }\n","        self.accumulation_steps = accumulation_steps\n","        self.train_targets = []\n","        self.train_preds = []\n","        self.valid_targets = []\n","        self.valid_preds = []\n","\n","    def fit(self, epochs, train_loader, valid_loader, save_path, patience):\n","        for n_epoch in range(1, epochs + 1):\n","            self.info_message(\"EPOCH: {}\", n_epoch)\n","            \n","            train_loss, train_score, train_time = self.train_epoch(train_loader)\n","            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n","            \n","            \n","            if self.best_train_score < train_score:\n","                self.best_train_score = train_score\n","\n","            self.hist['val_loss'].append(valid_loss)\n","            self.hist['train_loss'].append(train_loss)\n","            self.hist['val_score'].append(valid_score)\n","            self.hist['train_score'].append(train_score)\n","            \n","            self.info_message(\n","                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n","            )\n","            \n","            self.info_message(\n","                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n","            )\n","                \n","\n","            if self.best_valid_score < valid_score:\n","                self.info_message(\n","                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n","                )\n","                self.best_valid_score = valid_score\n","                self.best_valid_loss = valid_loss\n","                self.save_model(n_epoch, save_path)\n","                self.n_patience = 0\n","            else:\n","                self.n_patience += 1\n","            \n","            if self.n_patience >= patience:\n","                self.info_message(self.messages[\"patience\"], patience)\n","                break\n","                \n","        return self.best_valid_loss, self.best_valid_score\n","\n","    def train_epoch(self, train_loader):\n","        self.model.train()\n","        t = time.time()\n","        self.loss_meter.reset()\n","        self.score_meter.reset()\n","        \n","        self.optimizer.zero_grad()\n","        \n","        for step, batch in enumerate(train_loader, 1):\n","            X = batch[\"X\"].to(self.device)\n","            targets = batch[\"y\"].to(self.device)\n","            \n","            with torch.cuda.amp.autocast():  # Mixed precision\n","                outputs = self.model(X).squeeze(1)\n","                loss = self.criterion(outputs, targets) / self.accumulation_steps\n","            \n","            self.scaler.scale(loss).backward()\n","\n","            if step % self.accumulation_steps == 0:\n","                self.scaler.step(self.optimizer)\n","                self.scaler.update()\n","                self.optimizer.zero_grad()\n","                \n","            self.loss_meter.update(loss.detach().item() * self.accumulation_steps)\n","            self.score_meter.update(targets, outputs)\n","            \n","            self.train_targets.extend(targets.cpu().numpy())\n","            self.train_preds.extend(outputs.detach().cpu().numpy())\n","\n","            _loss, _score = self.loss_meter.avg, self.score_meter.avg\n","            message = 'Train Step {}/{}, train_loss: {:.9f}, train_score: {:.9f}'\n","            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n","        \n","        torch.cuda.empty_cache()\n","        return _loss, _score, int(time.time() - t)\n","    \n","    def valid_epoch(self, valid_loader):\n","        self.model.eval()\n","        t = time.time()\n","        self.loss_meter.reset()\n","        self.score_meter.reset()\n","\n","        for step, batch in enumerate(valid_loader, 1):\n","            with torch.no_grad():\n","                X = batch[\"X\"].to(self.device)\n","                targets = batch[\"y\"].to(self.device)\n","                \n","                with torch.cuda.amp.autocast():  # Mixed precision\n","                    outputs = self.model(X).squeeze(1)\n","                    loss = self.criterion(outputs, targets)\n","                \n","                self.loss_meter.update(loss.detach().item())\n","                self.score_meter.update(targets, outputs)\n","\n","                self.valid_targets.extend(targets.cpu().numpy())\n","                self.valid_preds.extend(outputs.detach().cpu().numpy())\n","\n","            _loss, _score = self.loss_meter.avg, self.score_meter.avg\n","            message = 'Valid Step {}/{}, valid_loss: {:.9f}, valid_score: {:.9f}'\n","            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n","        \n","        torch.cuda.empty_cache()\n","        return _loss, _score, int(time.time() - t)\n","\n","    def plot_loss(self):\n","        plt.title(\"Loss\")\n","        plt.xlabel(\"Training Epochs\")\n","        plt.ylabel(\"Loss\")\n","\n","        plt.plot(self.hist['train_loss'], label=\"Train\")\n","        plt.plot(self.hist['val_loss'], label=\"Validation\")\n","        plt.legend()\n","        plt.show()\n","    \n","    def plot_score(self):\n","        plt.title(\"Score\")\n","        plt.xlabel(\"Training Epochs\")\n","        plt.ylabel(\"Acc\")\n","\n","        plt.plot(self.hist['train_score'], label=\"Train\")\n","        plt.plot(self.hist['val_score'], label=\"Validation\")\n","        plt.legend()\n","        plt.show()\n","    \n","    def save_model(self, n_epoch, save_path):\n","        torch.save(\n","            {\n","                \"model_state_dict\": self.model.state_dict(),\n","                \"optimizer_state_dict\": self.optimizer.state_dict(),\n","                \"best_valid_score\": self.best_valid_score,\n","                \"n_epoch\": n_epoch,\n","            },\n","            save_path,\n","        )\n","    \n","    @staticmethod\n","    def info_message(message, *args, end=\"\\n\"):\n","        print(message.format(*args), end=end)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.743653Z","iopub.status.busy":"2024-07-11T09:25:54.743402Z","iopub.status.idle":"2024-07-11T09:25:54.755059Z","shell.execute_reply":"2024-07-11T09:25:54.754173Z","shell.execute_reply.started":"2024-07-11T09:25:54.743629Z"},"trusted":true},"outputs":[],"source":["print(len(df))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.760226Z","iopub.status.busy":"2024-07-11T09:25:54.759948Z","iopub.status.idle":"2024-07-11T09:25:54.773638Z","shell.execute_reply":"2024-07-11T09:25:54.772832Z","shell.execute_reply.started":"2024-07-11T09:25:54.760201Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['MGMT_value'])\n","\n","print(f\"Train size: {len(train_df)}\")\n","print(f\"Validation size: {len(valid_df)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.775011Z","iopub.status.busy":"2024-07-11T09:25:54.774616Z","iopub.status.idle":"2024-07-11T09:25:54.780473Z","shell.execute_reply":"2024-07-11T09:25:54.779706Z","shell.execute_reply.started":"2024-07-11T09:25:54.774986Z"},"trusted":true},"outputs":[],"source":["df_train_valid = pd.concat([train_df, valid_df]).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T09:25:54.782111Z","iopub.status.busy":"2024-07-11T09:25:54.781465Z","iopub.status.idle":"2024-07-11T15:05:05.655613Z","shell.execute_reply":"2024-07-11T15:05:05.649521Z","shell.execute_reply.started":"2024-07-11T09:25:54.782074Z"},"trusted":true},"outputs":[],"source":["import time\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","\n","skf = StratifiedKFold(n_splits=CFG.n_fold)\n","\n","start_time = time.time()\n","\n","losses = []\n","scores = []\n","\n","for fold, (train_index, val_index) in enumerate(skf.split(train_df, train_df['MGMT_value']), 1):\n","   print('-' * 30)\n","    print(f\"Fold {fold}\")\n","    \n","    train_fold_df = train_df.iloc[train_index]\n","    val_fold_df = train_df.iloc[val_index]\n","    \n","    train_retriever = DataRetriever(\n","        train_fold_df[\"BraTS21ID\"].values, \n","        train_fold_df[\"MGMT_value\"].values,\n","        train_transform\n","    )\n","    \n","    val_retriever = DataRetriever(\n","        val_fold_df[\"BraTS21ID\"].values, \n","        val_fold_df[\"MGMT_value\"].values\n","    )\n","    \n","    train_loader = DataLoader(\n","        train_retriever,\n","        batch_size=CFG.batch_size,\n","        shuffle=True,\n","        num_workers=4,\n","    )\n","    valid_loader = DataLoader(\n","        val_retriever, \n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=4,\n","    )\n","    \n","    model = Model()\n","    model.to(device)\n","    \n","    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","    criterion = nn.BCEWithLogitsLoss()\n","    \n","    loss_meter = LossMeter()\n","    score_meter = AccMeter()\n","    \n","    trainer = Trainer(\n","        model, \n","        device, \n","        optimizer, \n","        criterion, \n","        loss_meter, \n","        score_meter\n","    )\n","    \n","    loss, score = trainer.fit(\n","        CFG.n_epochs, \n","        train_loader, \n","        valid_loader, \n","        f\"best-model-{fold}.pth\", \n","        100,\n","    )\n","    \n","    losses.append(loss)\n","    scores.append(score)\n","    \n","    trainer.plot_loss()\n","    trainer.plot_score()\n","\n","elapsed_time = time.time() - start_time\n","print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n","print('Avg loss {}'.format(np.mean(losses)))\n","print('Avg score {}'.format(np.mean(scores)))\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":2420395,"sourceId":29653,"sourceType":"competition"},{"datasetId":251095,"sourceId":848739,"sourceType":"datasetVersion"},{"datasetId":1467572,"sourceId":2425289,"sourceType":"datasetVersion"},{"datasetId":5080437,"sourceId":8510886,"sourceType":"datasetVersion"},{"datasetId":5085361,"sourceId":8517589,"sourceType":"datasetVersion"},{"datasetId":5085380,"sourceId":8517619,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
