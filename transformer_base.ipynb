{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-07-18T04:22:55.956524Z","iopub.status.busy":"2021-07-18T04:22:55.955919Z","iopub.status.idle":"2021-07-18T04:22:56.527271Z","shell.execute_reply":"2021-07-18T04:22:56.526277Z","shell.execute_reply.started":"2021-07-18T04:22:55.956406Z"}},"source":["# Import things"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install efficientnet-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:31.774755Z","iopub.status.busy":"2024-06-09T08:26:31.774375Z","iopub.status.idle":"2024-06-09T08:26:34.162322Z","shell.execute_reply":"2024-06-09T08:26:34.161548Z","shell.execute_reply.started":"2024-06-09T08:26:31.774713Z"},"trusted":true},"outputs":[],"source":["package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\n","import sys \n","sys.path.append(package_path)\n","\n","import os\n","import glob\n","import time\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import pydicom\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch.utils import data as torch_data\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import efficientnet_pytorch\n","from efficientnet_pytorch import EfficientNet\n","\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:34.164277Z","iopub.status.busy":"2024-06-09T08:26:34.164007Z","iopub.status.idle":"2024-06-09T08:26:34.216032Z","shell.execute_reply":"2024-06-09T08:26:34.215142Z","shell.execute_reply.started":"2024-06-09T08:26:34.164251Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","seed = 123\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(seed)\n","\n","class CFG:\n","    img_size = 256\n","    n_frames = 10\n","    cnn_features = 256\n","    transformer_hidden = 256\n","    transformer_layers = 4\n","    n_fold = 3\n","    n_epochs = 50\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:34.217831Z","iopub.status.busy":"2024-06-09T08:26:34.21754Z","iopub.status.idle":"2024-06-09T08:26:34.229646Z","shell.execute_reply":"2024-06-09T08:26:34.228725Z","shell.execute_reply.started":"2024-06-09T08:26:34.217803Z"},"trusted":true},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.map = nn.Conv2d(in_channels=4, out_channels=3, kernel_size=1)\n","        self.net = EfficientNet.from_name(\"efficientnet-b0\")\n","        n_features = self.net._fc.in_features\n","        self.net._fc = nn.Linear(in_features=n_features, out_features=CFG.cnn_features, bias=True)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.map(x))\n","        out = self.net(x)\n","        return out\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.cnn = CNN()\n","        \n","        encoder_layers = nn.TransformerEncoderLayer(d_model=CFG.cnn_features, nhead=8, dim_feedforward=CFG.transformer_hidden, dropout=0.1)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=CFG.transformer_layers)\n","        \n","        self.fc = nn.Linear(CFG.cnn_features, 1, bias=True)\n","\n","    def forward(self, x):\n","        # x shape: BxTxCxHxW\n","        batch_size, timesteps, C, H, W = x.size()\n","        c_in = x.view(batch_size * timesteps, C, H, W)\n","        c_out = self.cnn(c_in)\n","        r_in = c_out.view(batch_size, timesteps, -1)\n","        r_in = r_in.permute(1, 0, 2)\n","        transformer_out = self.transformer_encoder(r_in)\n","        out = transformer_out.mean(dim=0)\n","        out = self.fc(out)\n","        return out\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:34.242692Z","iopub.status.busy":"2024-06-09T08:26:34.242441Z","iopub.status.idle":"2024-06-09T08:26:34.25159Z","shell.execute_reply":"2024-06-09T08:26:34.250795Z","shell.execute_reply.started":"2024-06-09T08:26:34.242662Z"},"trusted":true},"outputs":[],"source":["def load_image(path):\n","    image = cv2.imread(path, 0)\n","    if image is None or np.mean(image) < 1e-5:\n","        return np.zeros((CFG.img_size, CFG.img_size))\n","    \n","    image = cv2.resize(image, (CFG.img_size, CFG.img_size)) / 255\n","    return image.astype('f')\n","\n","def uniform_temporal_subsample(x, num_samples):\n","    '''\n","        Moddified from https://github.com/facebookresearch/pytorchvideo/blob/d7874f788bc00a7badfb4310a912f6e531ffd6d3/pytorchvideo/transforms/functional.py#L19\n","        Args:\n","            x: input list\n","            num_samples: The number of equispaced samples to be selected\n","        Returns:\n","            Output list     \n","    '''\n","    t = len(x)\n","    indices = torch.linspace(0, t - 1, num_samples)\n","    indices = torch.clamp(indices, 0, t - 1).long()\n","    return [x[i] for i in indices]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:34.25318Z","iopub.status.busy":"2024-06-09T08:26:34.252779Z","iopub.status.idle":"2024-06-09T08:26:34.266943Z","shell.execute_reply":"2024-06-09T08:26:34.266151Z","shell.execute_reply.started":"2024-06-09T08:26:34.253144Z"},"trusted":true},"outputs":[],"source":["class DataRetriever(Dataset):\n","    def __init__(self, paths, targets, transform=None):\n","        self.paths = paths\n","        self.targets = targets\n","        self.transform = transform\n","          \n","    def __len__(self):\n","        return len(self.paths)\n","    \n","    def read_video(self, vid_paths):\n","        video = [load_image(path) for path in vid_paths]\n","        if self.transform:\n","            seed = random.randint(0,99999)\n","            for i in range(len(video)):\n","                random.seed(seed)\n","                video[i] = self.transform(image=video[i])[\"image\"]\n","        \n","        video = [torch.tensor(frame, dtype=torch.float32) for frame in video]\n","        if len(video)==0:\n","            video = torch.zeros(CFG.n_frames, CFG.img_size, CFG.img_size)\n","        else:\n","            video = torch.stack(video) # T * C * H * W\n","#         video = torch.transpose(video, 0, 1) # C * T * H * W\n","        return video\n","    \n","    def __getitem__(self, index):\n","        _id = self.paths[index]\n","        patient_path = f\"../input/rsna-miccai-png/train/{str(_id).zfill(5)}/\"\n","        channels = []\n","        for t in [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]:\n","            t_paths = sorted(\n","                glob.glob(os.path.join(patient_path, t, \"*\")), \n","                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n","            )\n","            num_samples = CFG.n_frames\n","            if len(t_paths) < num_samples:\n","                in_frames_path = t_paths\n","            else:\n","                in_frames_path = uniform_temporal_subsample(t_paths, num_samples)\n","            \n","            channel = self.read_video(in_frames_path)\n","            if channel.shape[0] == 0:\n","                print(\"1 channel empty\")\n","                channel = torch.zeros(num_samples, CFG.img_size, CFG.img_size)\n","            channels.append(channel)\n","            \n","        channels = torch.stack(channels).transpose(0,1)\n","        \n","        y = torch.tensor(self.targets[index], dtype=torch.float)\n","        return {\"X\": channels.float(), \"y\": y}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:34.269479Z","iopub.status.busy":"2024-06-09T08:26:34.269187Z","iopub.status.idle":"2024-06-09T08:26:35.226526Z","shell.execute_reply":"2024-06-09T08:26:35.225756Z","shell.execute_reply.started":"2024-06-09T08:26:34.269451Z"},"trusted":true},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","train_transform = A.Compose([\n","                                A.HorizontalFlip(p=0.5),\n","                                A.ShiftScaleRotate(\n","                                    shift_limit=0.0625, \n","                                    scale_limit=0.1, \n","                                    rotate_limit=10, \n","                                    p=0.5\n","                                ),\n","                                A.RandomBrightnessContrast(p=0.5),\n","                            ])\n","valid_transform = A.Compose([\n","                            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.233074Z","iopub.status.busy":"2024-06-09T08:26:35.232693Z","iopub.status.idle":"2024-06-09T08:26:35.266703Z","shell.execute_reply":"2024-06-09T08:26:35.265893Z","shell.execute_reply.started":"2024-06-09T08:26:35.233025Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n","df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.272763Z","iopub.status.busy":"2024-06-09T08:26:35.272444Z","iopub.status.idle":"2024-06-09T08:26:35.280829Z","shell.execute_reply":"2024-06-09T08:26:35.279953Z","shell.execute_reply.started":"2024-06-09T08:26:35.272736Z"},"trusted":true},"outputs":[],"source":["class LossMeter:\n","    def __init__(self):\n","        self.avg = 0\n","        self.n = 0\n","\n","    def update(self, val):\n","        self.n += 1\n","        # incremental update\n","        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n","\n","        \n","class AccMeter:\n","    def __init__(self):\n","        self.avg = 0\n","        self.n = 0\n","        \n","    def update(self, y_true, y_pred):\n","        y_true = y_true.cpu().numpy().astype(int)\n","        y_pred = y_pred.cpu().numpy() >= 0\n","        last_n = self.n\n","        self.n += len(y_true)\n","        true_count = np.sum(y_true == y_pred)\n","        # incremental update\n","        self.avg = true_count / self.n + last_n / self.n * self.avg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.282481Z","iopub.status.busy":"2024-06-09T08:26:35.282194Z","iopub.status.idle":"2024-06-09T08:26:35.310892Z","shell.execute_reply":"2024-06-09T08:26:35.310073Z","shell.execute_reply.started":"2024-06-09T08:26:35.282454Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(\n","        self, \n","        model, \n","        device, \n","        optimizer, \n","        criterion, \n","        loss_meter, \n","        score_meter\n","    ):\n","        self.model = model\n","        self.device = device\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.loss_meter = loss_meter\n","        self.score_meter = score_meter\n","        self.hist = {'val_loss':[],\n","                     'val_score':[],\n","                     'train_loss':[],\n","                     'train_score':[]\n","                    }\n","        \n","        self.best_valid_score = -np.inf\n","        self.best_valid_loss = np.inf\n","        self.n_patience = 0\n","        \n","        self.messages = {\n","            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n","            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n","            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n","        }\n","    \n","    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n","        for n_epoch in range(1, epochs + 1):\n","            self.info_message(\"EPOCH: {}\", n_epoch)\n","            \n","            train_loss, train_score, train_time = self.train_epoch(train_loader)\n","            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n","            \n","            self.info_message(\n","                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n","            )\n","            \n","            self.info_message(\n","                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n","            )\n","\n","            if self.best_valid_score < valid_score:\n","                self.info_message(\n","                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n","                )\n","                self.best_valid_score = valid_score\n","                self.best_valid_loss = valid_loss\n","                self.save_model(n_epoch, save_path)\n","                self.n_patience = 0\n","            else:\n","                self.n_patience += 1\n","            \n","            if self.n_patience >= patience:\n","                self.info_message(self.messages[\"patience\"], patience)\n","                break\n","                \n","        return self.best_valid_loss, self.best_valid_score\n","            \n","    def train_epoch(self, train_loader):\n","        self.model.train()\n","        t = time.time()\n","        train_loss = self.loss_meter()\n","        train_score = self.score_meter()\n","        \n","        for step, batch in enumerate(train_loader, 1):\n","            X = batch[\"X\"].to(self.device)\n","            targets = batch[\"y\"].to(self.device)\n","            self.optimizer.zero_grad()\n","            outputs = self.model(X).squeeze(1)\n","            \n","            loss = self.criterion(outputs, targets)\n","            loss.backward()\n","\n","            train_loss.update(loss.detach().item())\n","            train_score.update(targets, outputs.detach())\n","\n","            self.optimizer.step()\n","            \n","            _loss, _score = train_loss.avg, train_score.avg\n","            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n","            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n","        \n","        return train_loss.avg, train_score.avg, int(time.time() - t)\n","    \n","    def valid_epoch(self, valid_loader):\n","        self.model.eval()\n","        t = time.time()\n","        valid_loss = self.loss_meter()\n","        valid_score = self.score_meter()\n","\n","        for step, batch in enumerate(valid_loader, 1):\n","            with torch.no_grad():\n","                X = batch[\"X\"].to(self.device)\n","                targets = batch[\"y\"].to(self.device)\n","\n","                outputs = self.model(X).squeeze(1)\n","                loss = self.criterion(outputs, targets)\n","\n","                valid_loss.update(loss.detach().item())\n","                valid_score.update(targets, outputs)\n","                \n","            _loss, _score = valid_loss.avg, valid_score.avg\n","            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n","            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n","        \n","        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n","    \n","    def plot_loss(self):\n","        plt.title(\"Loss\")\n","        plt.xlabel(\"Training Epochs\")\n","        plt.ylabel(\"Loss\")\n","\n","        plt.plot(self.hist['train_loss'], label=\"Train\")\n","        plt.plot(self.hist['val_loss'], label=\"Validation\")\n","        plt.legend()\n","        plt.show()\n","    \n","    def plot_score(self):\n","        plt.title(\"Score\")\n","        plt.xlabel(\"Training Epochs\")\n","        plt.ylabel(\"Acc\")\n","\n","        plt.plot(self.hist['train_score'], label=\"Train\")\n","        plt.plot(self.hist['val_score'], label=\"Validation\")\n","        plt.legend()\n","        plt.show()\n","    \n","    def save_model(self, n_epoch, save_path):\n","        torch.save(\n","            {\n","                \"model_state_dict\": self.model.state_dict(),\n","                \"optimizer_state_dict\": self.optimizer.state_dict(),\n","                \"best_valid_score\": self.best_valid_score,\n","                \"n_epoch\": n_epoch,\n","            },\n","            save_path,\n","        )\n","    \n","    @staticmethod\n","    def info_message(message, *args, end=\"\\n\"):\n","        print(message.format(*args), end=end)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.312351Z","iopub.status.busy":"2024-06-09T08:26:35.31205Z","iopub.status.idle":"2024-06-09T08:26:35.331532Z","shell.execute_reply":"2024-06-09T08:26:35.330609Z","shell.execute_reply.started":"2024-06-09T08:26:35.312324Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","df_train_valid, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['MGMT_value'])\n","train_df, valid_df = train_test_split(df_train_valid, test_size=0.1111, random_state=42, stratify=df_train_valid['MGMT_value'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.33333Z","iopub.status.busy":"2024-06-09T08:26:35.332787Z","iopub.status.idle":"2024-06-09T08:26:35.343695Z","shell.execute_reply":"2024-06-09T08:26:35.34277Z","shell.execute_reply.started":"2024-06-09T08:26:35.333279Z"},"trusted":true},"outputs":[],"source":["df_train_valid = pd.concat([train_df, valid_df]).reset_index(drop=True)\n","df_train_valid.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-09T08:26:35.345444Z","iopub.status.busy":"2024-06-09T08:26:35.345092Z","iopub.status.idle":"2024-06-09T10:21:26.298419Z","shell.execute_reply":"2024-06-09T10:21:26.297287Z","shell.execute_reply.started":"2024-06-09T08:26:35.345404Z"},"trusted":true},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CFG.n_fold)\n","\n","start_time = time.time()\n","\n","losses = []\n","scores = []\n","\n","for fold, (train_index, val_index) in enumerate(skf.split(np.zeros(len(df_train_valid)), df_train_valid['MGMT_value']), 1):\n","    print('-'*30)\n","    print(f\"Fold {fold}\")\n","    \n","    train_df = df_train_valid.loc[train_index]\n","    val_df = df_train_valid.loc[val_index]\n","    \n","    train_retriever = DataRetriever(\n","        train_df[\"BraTS21ID\"].values, \n","        train_df[\"MGMT_value\"].values,\n","        train_transform\n","    )\n","    \n","    val_retriever = DataRetriever(\n","        val_df[\"BraTS21ID\"].values, \n","        val_df[\"MGMT_value\"].values\n","    )\n","    \n","    train_loader = torch_data.DataLoader(\n","        train_retriever,\n","        batch_size=2,\n","        shuffle=True,\n","        num_workers=8,\n","    )\n","    valid_loader = torch_data.DataLoader(\n","        val_retriever, \n","        batch_size=2,\n","        shuffle=False,\n","        num_workers=8,\n","    )\n","    \n","    model = Model()\n","    model.to(device)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    criterion = F.binary_cross_entropy_with_logits\n","    \n","    trainer = Trainer(\n","        model, \n","        device, \n","        optimizer, \n","        criterion, \n","        LossMeter, \n","        AccMeter\n","    )\n","    loss, score = trainer.fit(\n","        CFG.n_epochs, \n","        train_loader, \n","        valid_loader, \n","        f\"best-model-{fold}.pth\", \n","        100,\n","    )\n","    losses.append(loss)\n","    scores.append(score)\n","    \n","    trainer.plot_loss()\n","    trainer.plot_score()\n","    \n","elapsed_time = time.time() - start_time\n","print('\\nTraining complete in {:.0f}m {:.0f}s'.format(elapsed_time // 60, elapsed_time % 60))\n","print('Avg loss {}'.format(np.mean(losses)))\n","print('Avg score {}'.format(np.mean(scores)))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":2420395,"sourceId":29653,"sourceType":"competition"},{"datasetId":251095,"sourceId":848739,"sourceType":"datasetVersion"},{"datasetId":1467572,"sourceId":2425289,"sourceType":"datasetVersion"}],"dockerImageVersionId":30121,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
